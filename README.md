# Project 4: Option 1

## Elizabeth Brown

#What it Does
Scrapes all the state links from the main page of the nation parks website.

Creates multiple BeautifulSoup instances and caches them in a JSON file.

Crawls from link to link scraping data about national sites for each state.

Loads that data onto a csv file.

# How it Runs
It runs off a single URL (the national parks site URL)

type "python [name of file]"
and wait for the magic to happen.

# Dependencies
BeautifulSoup
requests
json
csv
advanced_expiry_caching
